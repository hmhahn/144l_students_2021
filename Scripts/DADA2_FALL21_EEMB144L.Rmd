---
title: "DADA2_FALL21_EEMB144L"
author: "Hope Hahn"
date: "11/22/2021"
output: github_document
---

# Load packages
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(dada2)
library(ShortRead)
```

# Import data

```{r}
#save the path to the directory with a COPY of your unzipped fastq files that you WILL work with. MAKE SURE YOU HAVE ANOTHER DIRECTORY WITH THE FILES THAT YOU WILL NEVER DIRECTLY WORK WITH. 

path <- "~/Desktop/github/144l_students_2021/Input_Data/week9/Kelp_Remin_fastq" #make sure there is no / at the end of the path
#also make sure there are no unzipped files in this directory

#store the names of fwd and rv files as lists
fnFs <- list.files(path, pattern = "_R1_001.fastq", full.names = TRUE)
fnRs <- list.files(path, pattern = "_R2_001.fastq", full.names = TRUE)
```

# Retrieve orientation of primers


```{r}
FWD = "GTGYCAGCMGCCGCGGTAA"
REV = "GGACTACNVGGGTWTCTAAT"

#now store all orientations of fwd and rvs primers 
allOrients <- function(primer) {
  # Biostrings works w/ DNAString objects rather than character vectors
  require(Biostrings)
  dna <- DNAString(primer)
  orients <- c(Forward = dna, Complement = complement(dna), Reverse = reverse(dna), 
              RevComp = reverseComplement(dna))
  #Convert back to character vector
  return(sapply(orients, toString))
  }
  
#Store the fwd and rvs orientations separately 
FWD.orients <- allOrients(FWD)
REV.orients <- allOrients(REV)

#view the orientations of the primers
FWD.orients
REV.orients
```

#search for Primers

```{r}
primerHits <- function(primer, fn) {
  #Counts number of reads in which the primer is found
  nhits <- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE)
  return(sum(nhits >0))
  }
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs[[1]]), 
      FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs[[1]]), 
      REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs[[1]]), 
      REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs[[1]]))
```


# Insepct read quality profiles 

You should look at least some of the quality profiles to assess the quality of the sequencing run. 

## Forward reads 

```{r fig.height=10, fig.width=12}
plotQualityProfile(fnFs[1:12])
```

# Reverse reads 

```{r fig.height=10, fig.width=12}
plotQualityProfile(fnRs[1:12])
```


# Filtering and Trimming 

```{r}
#Get the sample names
#define the basename of the fnFs as the first part of each fastq file name until "_L"
#apply this to all samples
sample.names <- sapply(strsplit(basename(fnFs), "_L"), `[`, 1)
sample.names
#created a "filtered" folder in the working directory as a place to put all the new filtered fastQ files. 
filt_path <- file.path(path, "filtered")
#add the appropriate designation string to any new files made that will be put into the "filtered" folder
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq"))
```


```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen = c(240, 150), maxN = 0, maxEE = c(2,2), truncQ = 2, rm.phix = TRUE, compress = TRUE)
#look at this output. This tells you how many reads were removed. 
out
```



# Learn the error rates

```{r}
errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)
```


```{r echo= FALSE, warning = FALSE, message = FALSE, fig.height=10, fig.width=12, fig.align="center", warning= FALSE}
plotErrors(errF, nominalQ = TRUE)
```

```{r echo= FALSE, warning = FALSE, message = FALSE, fig.height=10, fig.width=12, fig.align="center", warning= FALSE}
plotErrors(errR, nominalQ = TRUE)
```

# Dereplication 


```{r}
derepFs <- derepFastq(filtFs, verbose = TRUE)
derepRs <- derepFastq(filtRs, verbose = TRUE)
# Name the derep-class objects by the sample names 
names(derepFs) <- sample.names
names(derepRs) <- sample.names
```


# Infer sequence variants 


```{r}
dadaFs <- dada(derepFs, err = errF, multithread = TRUE)
dadaRs <- dada(derepRs, err = errR, multithread = TRUE)
```


```{r}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = TRUE, trimOverhang = T)
```


```{r}
head(mergers[[1]])
```


```{r}
#tutorial says week 5/6, just save in Input & Output data for Week 7 (we are on a different schedule this year than previous)
saveRDS(mergers, "~/Desktop/github/144l_students_2021/Output_Data/week7//dada_merged.rds")
saveRDS(mergers, "~/Desktop/github//144l_students_2021/Input_Data/week7/dada_merged.rds")
```



```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # samples by unique sequence
```



```{r}
table(nchar(getSequences(seqtab)))
```

# Remove the Chimeras 


```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, verbose = TRUE)
dim(seqtab.nochim)
```

check the proportion of sequences that are not chimeras
```{r}
sum(seqtab.nochim)/sum(seqtab)
```

# Assign taxonomy using a reference database

here we are referencing the Silva database

```{r}
taxa <- assignTaxonomy(seqtab.nochim, "~/Desktop/github/144l_students_2021/Input_Data/week7/Reference_Database/silva_nr_v138_train_set.fa", multithread = TRUE)

```

This took ~90s to complete on a 2021 MacBook Pro

create a table out of the taxa data (one with the sequences and taxonomic assignments, one with just all the taxa)

these are the tables you want to save!! 

```{r}
saveRDS(t(seqtab.nochim), "~/Desktop/github/144l_students_2021/Output_Data/week7/seqtab-nochimtaxa.rds")
saveRDS(taxa, "~/Desktop/github/144l_students_2021/Output_Data/week7/taxa.rds")

#save in both Output and Input data folders for week7

saveRDS(t(seqtab.nochim), "~/Desktop/github/144l_students_2021/Input_Data/week7/seqtab-nochimtaxa.rds")
saveRDS(taxa, "~/Desktop/github/144l_students_2021/Input_Data/week7/taxa.rds")
        
```